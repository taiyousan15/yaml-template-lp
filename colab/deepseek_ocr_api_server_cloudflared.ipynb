{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek OCR API Server for Google Colab (Cloudflare Tunnelç‰ˆ)\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯Google Colabä¸Šã§DeepSeek OCRã‚’APIã‚µãƒ¼ãƒãƒ¼ã¨ã—ã¦å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "## Cloudflare Tunnelã®åˆ©ç‚¹\n",
    "- âœ… **èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ä¸è¦**ï¼ˆngrokã‚ˆã‚Šç°¡å˜ï¼‰\n",
    "- âœ… **å®Œå…¨ç„¡æ–™**\n",
    "- âœ… **å®‰å®šæ€§ãŒé«˜ã„**\n",
    "- âœ… **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒç°¡å˜**\n",
    "\n",
    "## ä½¿ã„æ–¹\n",
    "1. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  â†’ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ â†’ **GPU** ã‚’é¸æŠ\n",
    "2. ã™ã¹ã¦ã®ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œ\n",
    "3. è¡¨ç¤ºã•ã‚ŒãŸCloudflare URLã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã€MacBook Proã®`.env`ã«è¨­å®š\n",
    "\n",
    "## å¿…è¦ãªã‚‚ã®\n",
    "- Google ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã¿ï¼ˆè¿½åŠ ç™»éŒ²ä¸è¦ï¼ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPUç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cloudflaredã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloudflaredã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
    "!sudo dpkg -i cloudflared-linux-amd64.deb\n",
    "!rm cloudflared-linux-amd64.deb\n",
    "\n",
    "# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª\n",
    "!cloudflared --version\n",
    "\n",
    "print(\"âœ… Cloudflaredã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek OCRä¾å­˜é–¢ä¿‚\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q transformers==4.46.3\n",
    "!pip install -q tokenizers==0.20.3\n",
    "!pip install -q einops addict easydict\n",
    "!pip install -q Pillow PyYAML opencv-python-headless\n",
    "!pip install -q flask flask-cors\n",
    "\n",
    "# Flash Attentionï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€é«˜é€ŸåŒ–ï¼‰\n",
    "!pip install -q flash-attn==2.7.3 --no-build-isolation || echo \"Flash Attention ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰\"\n",
    "\n",
    "print(\"âœ… ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DeepSeek OCRãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®å®Ÿè£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "class DeepSeekOCRProcessor:\n",
    "    \"\"\"DeepSeek-OCRã‚’ä½¿ç”¨ã—ã¦LPç”»åƒã‚’å‡¦ç†\"\"\"\n",
    "\n",
    "    def __init__(self, model_name='deepseek-ai/DeepSeek-OCR'):\n",
    "        print(f\"Loading DeepSeek-OCR model: {model_name}\")\n",
    "        print(\"åˆå›ã¯5-10åˆ†ã‹ã‹ã‚Šã¾ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            _attn_implementation='flash_attention_2',\n",
    "            trust_remote_code=True,\n",
    "            use_safetensors=True\n",
    "        )\n",
    "\n",
    "        self.model = self.model.eval().cuda().to(torch.bfloat16)\n",
    "        print(\"âœ… Model loaded successfully\")\n",
    "\n",
    "    def process_image_to_yaml(self, image_data, output_path='/tmp/deepseek_output'):\n",
    "        \"\"\"\n",
    "        ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆbase64ã¾ãŸã¯ãƒã‚¤ãƒˆï¼‰ã‹ã‚‰YAMLã‚’ç”Ÿæˆ\n",
    "        \"\"\"\n",
    "        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        temp_image_path = os.path.join(output_path, 'temp_image.png')\n",
    "        \n",
    "        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜\n",
    "        if isinstance(image_data, str):\n",
    "            # base64ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
    "            image_bytes = base64.b64decode(image_data)\n",
    "            with open(temp_image_path, 'wb') as f:\n",
    "                f.write(image_bytes)\n",
    "        else:\n",
    "            # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "            with open(temp_image_path, 'wb') as f:\n",
    "                f.write(image_data)\n",
    "        \n",
    "        # DeepSeek OCRå®Ÿè¡Œ\n",
    "        prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n",
    "        \n",
    "        result = self.model.infer(\n",
    "            self.tokenizer,\n",
    "            prompt=prompt,\n",
    "            image_file=temp_image_path,\n",
    "            output_path=output_path,\n",
    "            base_size=1024,\n",
    "            image_size=640,\n",
    "            crop_mode=True,\n",
    "            save_results=False,\n",
    "            test_compress=True\n",
    "        )\n",
    "        \n",
    "        # Markdownã‚’å–å¾—\n",
    "        if isinstance(result, dict):\n",
    "            markdown_text = result.get('text', '') or result.get('content', '')\n",
    "        else:\n",
    "            markdown_text = str(result)\n",
    "        \n",
    "        # Markdown â†’ YAMLå¤‰æ›\n",
    "        yaml_text = self.markdown_to_yaml(markdown_text)\n",
    "        \n",
    "        return {\n",
    "            'yaml': yaml_text,\n",
    "            'markdown': markdown_text\n",
    "        }\n",
    "\n",
    "    def markdown_to_yaml(self, markdown_text):\n",
    "        \"\"\"Markdown â†’ YAMLå¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰\"\"\"\n",
    "        sections = []\n",
    "        lines = markdown_text.split('\\n')\n",
    "        current_section = None\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            if line.startswith('#'):\n",
    "                if current_section:\n",
    "                    sections.append(current_section)\n",
    "                \n",
    "                heading_text = line.lstrip('#').strip()\n",
    "                current_section = {\n",
    "                    'type': 'content',\n",
    "                    'texts': [{'content': heading_text, 'role': 'headline'}],\n",
    "                    'buttons': [],\n",
    "                    'items': []\n",
    "                }\n",
    "            elif current_section:\n",
    "                current_section['texts'].append({'content': line, 'role': 'body'})\n",
    "        \n",
    "        if current_section:\n",
    "            sections.append(current_section)\n",
    "        \n",
    "        if not sections:\n",
    "            sections.append({\n",
    "                'type': 'content',\n",
    "                'texts': [{'content': markdown_text[:500], 'role': 'body'}],\n",
    "                'buttons': [],\n",
    "                'items': []\n",
    "            })\n",
    "        \n",
    "        yaml_data = {\n",
    "            'meta': {\n",
    "                'generator': 'DeepSeek-OCR',\n",
    "                'template_version': '2.0'\n",
    "            },\n",
    "            'sections': {f'section{i+1}': s for i, s in enumerate(sections)}\n",
    "        }\n",
    "        \n",
    "        return yaml.dump(yaml_data, allow_unicode=True, default_flow_style=False)\n",
    "\n",
    "# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆåˆå›ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã¿ï¼‰\n",
    "processor = None\n",
    "\n",
    "def get_processor():\n",
    "    global processor\n",
    "    if processor is None:\n",
    "        processor = DeepSeekOCRProcessor()\n",
    "    return processor\n",
    "\n",
    "print(\"âœ… DeepSeekOCRProcessorå®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Flask APIã‚µãƒ¼ãƒãƒ¼ã®å®Ÿè£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # CORSæœ‰åŠ¹åŒ–\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({\n",
    "        'status': 'ok',\n",
    "        'service': 'DeepSeek-OCR API Server (Cloudflare Tunnel)',\n",
    "        'gpu': torch.cuda.is_available(),\n",
    "        'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None\n",
    "    })\n",
    "\n",
    "@app.route('/ocr', methods=['POST'])\n",
    "def ocr_endpoint():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯base64ãƒ‡ãƒ¼ã‚¿\n",
    "        if 'file' in request.files:\n",
    "            file = request.files['file']\n",
    "            image_data = file.read()\n",
    "        elif request.is_json and 'image' in request.json:\n",
    "            image_data = request.json['image']  # base64\n",
    "        else:\n",
    "            return jsonify({'success': False, 'error': 'No image provided'}), 400\n",
    "        \n",
    "        # DeepSeek OCRå®Ÿè¡Œ\n",
    "        proc = get_processor()\n",
    "        result = proc.process_image_to_yaml(image_data)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'yaml': result['yaml'],\n",
    "            'markdown': result['markdown'],\n",
    "            'processingTime': processing_time * 1000,  # ms\n",
    "            'metadata': {\n",
    "                'modelType': 'DeepSeek-OCR',\n",
    "                'processingTime': processing_time * 1000\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "print(\"âœ… Flask APIã‚µãƒ¼ãƒãƒ¼å®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cloudflare Tunnelã®èµ·å‹•\n",
    "\n",
    "**èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ä¸è¦ï¼** ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ã§OKã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import subprocess\n",
    "import time\n",
    "import re\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“¦ DeepSeek-OCRãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "print(\"åˆå›ã¯5-10åˆ†ã‹ã‹ã‚Šã¾ã™ã€‚ã‚³ãƒ¼ãƒ’ãƒ¼ã§ã‚‚é£²ã‚“ã§ãŠå¾…ã¡ãã ã•ã„â˜•\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "get_processor()\n",
    "\n",
    "print(\"\\nâœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Flaskã‚µãƒ¼ãƒãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•\n",
    "def run_flask():\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)\n",
    "\n",
    "flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
    "flask_thread.start()\n",
    "\n",
    "# FlaskãŒèµ·å‹•ã™ã‚‹ã¾ã§å¾…æ©Ÿ\n",
    "time.sleep(3)\n",
    "\n",
    "# Cloudflare Tunnelã‚’èµ·å‹•\n",
    "print(\"ğŸŒ Cloudflare Tunnelã‚’èµ·å‹•ä¸­...\\n\")\n",
    "\n",
    "cloudflared_process = subprocess.Popen(\n",
    "    ['cloudflared', 'tunnel', '--url', 'http://localhost:5000'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "# Cloudflare URLã‚’å–å¾—\n",
    "public_url = None\n",
    "for line in cloudflared_process.stdout:\n",
    "    print(line.strip())\n",
    "    \n",
    "    # URLã‚’æŠ½å‡º\n",
    "    if 'trycloudflare.com' in line or 'https://' in line:\n",
    "        match = re.search(r'https://[a-zA-Z0-9-]+\\.trycloudflare\\.com', line)\n",
    "        if match:\n",
    "            public_url = match.group(0)\n",
    "            break\n",
    "\n",
    "if public_url:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ DeepSeek OCR APIã‚µãƒ¼ãƒãƒ¼èµ·å‹•å®Œäº†ï¼\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nğŸ“¡ å…¬é–‹URL: {public_url}\")\n",
    "    print(f\"\\nâœ… ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: {public_url}/health\")\n",
    "    print(f\"âœ… OCRã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {public_url}/ocr\")\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"ğŸ’¡ MacBook Proã§ã®è¨­å®šæ–¹æ³•:\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"\\n1. .envãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¿½åŠ :\")\n",
    "    print(f\"   DEEPSEEK_COLAB_URL={public_url}\")\n",
    "    print(\"\\n2. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•:\")\n",
    "    print(\"   npm run dev\")\n",
    "    print(\"\\n3. http://localhost:3000 ã«ã‚¢ã‚¯ã‚»ã‚¹\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âš ï¸  é‡è¦ãªæ³¨æ„äº‹é …\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"â€¢ ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ç¶šã‘ã¦ã„ã‚‹é™ã‚Šã‚µãƒ¼ãƒãƒ¼ã¯ç¨¼åƒã—ã¾ã™\")\n",
    "    print(\"â€¢ Colabã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ‡ã‚ŒãŸã‚‰å†èµ·å‹•ãŒå¿…è¦ã§ã™ï¼ˆç„¡æ–™ç‰ˆ:12æ™‚é–“ï¼‰\")\n",
    "    print(\"â€¢ URLã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«å¤‰ã‚ã‚Šã¾ã™\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # ã‚µãƒ¼ãƒãƒ¼ã‚’ç¨¼åƒã—ç¶šã‘ã‚‹\n",
    "    try:\n",
    "        cloudflared_process.wait()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâ¹ï¸  ã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¾ã—ãŸ\")\n",
    "        cloudflared_process.terminate()\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Cloudflare URLã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "    print(\"ä¸Šè¨˜ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒ†ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "\n",
    "åˆ¥ã®ã‚»ãƒ«ã§ã€APIãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ãƒ†ã‚¹ãƒˆã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# ä¸Šã§è¡¨ç¤ºã•ã‚ŒãŸå…¬é–‹URLã‚’ä½¿ç”¨\n",
    "API_URL = \"YOUR_CLOUDFLARE_URL\"  # ä¾‹: https://xxxx.trycloudflare.com\n",
    "\n",
    "if API_URL != \"YOUR_CLOUDFLARE_URL\":\n",
    "    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯\n",
    "    try:\n",
    "        response = requests.get(f\"{API_URL}/health\", timeout=10)\n",
    "        print(\"âœ… ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æˆåŠŸ:\")\n",
    "        print(response.json())\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ API_URLã‚’è¨­å®šã—ã¦ãã ã•ã„\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
