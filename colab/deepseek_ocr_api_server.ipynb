{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek OCR API Server for Google Colab\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯Google Colabä¸Šã§DeepSeek OCRã‚’APIã‚µãƒ¼ãƒãƒ¼ã¨ã—ã¦å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "## ä½¿ã„æ–¹\n",
    "1. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  â†’ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ â†’ GPU ã‚’é¸æŠ\n",
    "2. ã™ã¹ã¦ã®ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œ\n",
    "3. ngrok URLã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã€MacBook Proã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®DEEPSEEK_OCR_URLã«è¨­å®š\n",
    "\n",
    "## å¿…è¦ãªã‚‚ã®\n",
    "- Google ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "- ngrok ã‚¢ã‚«ã‚¦ãƒ³ãƒˆï¼ˆç„¡æ–™ï¼‰: https://ngrok.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPUç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek OCRä¾å­˜é–¢ä¿‚\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q transformers==4.46.3\n",
    "!pip install -q tokenizers==0.20.3\n",
    "!pip install -q einops addict easydict\n",
    "!pip install -q Pillow PyYAML opencv-python-headless\n",
    "!pip install -q flask flask-cors pyngrok\n",
    "\n",
    "# Flash Attentionï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€é«˜é€ŸåŒ–ï¼‰\n",
    "!pip install -q flash-attn==2.7.3 --no-build-isolation || echo \"Flash Attention ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰\"\n",
    "\n",
    "print(\"âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DeepSeek OCRãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®å®Ÿè£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "class DeepSeekOCRProcessor:\n",
    "    \"\"\"DeepSeek-OCRã‚’ä½¿ç”¨ã—ã¦LPç”»åƒã‚’å‡¦ç†\"\"\"\n",
    "\n",
    "    def __init__(self, model_name='deepseek-ai/DeepSeek-OCR'):\n",
    "        print(f\"Loading DeepSeek-OCR model: {model_name}\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            _attn_implementation='flash_attention_2',\n",
    "            trust_remote_code=True,\n",
    "            use_safetensors=True\n",
    "        )\n",
    "\n",
    "        self.model = self.model.eval().cuda().to(torch.bfloat16)\n",
    "        print(\"âœ… Model loaded successfully\")\n",
    "\n",
    "    def process_image_to_yaml(self, image_data, output_path='/tmp/deepseek_output'):\n",
    "        \"\"\"\n",
    "        ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆbase64ã¾ãŸã¯ãƒã‚¤ãƒˆï¼‰ã‹ã‚‰YAMLã‚’ç”Ÿæˆ\n",
    "        \"\"\"\n",
    "        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        temp_image_path = os.path.join(output_path, 'temp_image.png')\n",
    "        \n",
    "        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜\n",
    "        if isinstance(image_data, str):\n",
    "            # base64ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
    "            image_bytes = base64.b64decode(image_data)\n",
    "            with open(temp_image_path, 'wb') as f:\n",
    "                f.write(image_bytes)\n",
    "        else:\n",
    "            # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "            with open(temp_image_path, 'wb') as f:\n",
    "                f.write(image_data)\n",
    "        \n",
    "        # DeepSeek OCRå®Ÿè¡Œ\n",
    "        prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n",
    "        \n",
    "        result = self.model.infer(\n",
    "            self.tokenizer,\n",
    "            prompt=prompt,\n",
    "            image_file=temp_image_path,\n",
    "            output_path=output_path,\n",
    "            base_size=1024,\n",
    "            image_size=640,\n",
    "            crop_mode=True,\n",
    "            save_results=False,\n",
    "            test_compress=True\n",
    "        )\n",
    "        \n",
    "        # Markdownã‚’å–å¾—\n",
    "        if isinstance(result, dict):\n",
    "            markdown_text = result.get('text', '') or result.get('content', '')\n",
    "        else:\n",
    "            markdown_text = str(result)\n",
    "        \n",
    "        # Markdown â†’ YAMLå¤‰æ›\n",
    "        yaml_text = self.markdown_to_yaml(markdown_text)\n",
    "        \n",
    "        return {\n",
    "            'yaml': yaml_text,\n",
    "            'markdown': markdown_text\n",
    "        }\n",
    "\n",
    "    def markdown_to_yaml(self, markdown_text):\n",
    "        \"\"\"Markdown â†’ YAMLå¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰\"\"\"\n",
    "        sections = []\n",
    "        lines = markdown_text.split('\\n')\n",
    "        current_section = None\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            if line.startswith('#'):\n",
    "                if current_section:\n",
    "                    sections.append(current_section)\n",
    "                \n",
    "                heading_text = line.lstrip('#').strip()\n",
    "                current_section = {\n",
    "                    'type': 'content',\n",
    "                    'texts': [{'content': heading_text, 'role': 'headline'}],\n",
    "                    'buttons': [],\n",
    "                    'items': []\n",
    "                }\n",
    "            elif current_section:\n",
    "                current_section['texts'].append({'content': line, 'role': 'body'})\n",
    "        \n",
    "        if current_section:\n",
    "            sections.append(current_section)\n",
    "        \n",
    "        yaml_data = {\n",
    "            'meta': {'generator': 'DeepSeek-OCR'},\n",
    "            'sections': {f'section{i+1}': s for i, s in enumerate(sections)}\n",
    "        }\n",
    "        \n",
    "        return yaml.dump(yaml_data, allow_unicode=True, default_flow_style=False)\n",
    "\n",
    "# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆåˆå›ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã¿ï¼‰\n",
    "processor = None\n",
    "\n",
    "def get_processor():\n",
    "    global processor\n",
    "    if processor is None:\n",
    "        processor = DeepSeekOCRProcessor()\n",
    "    return processor\n",
    "\n",
    "print(\"âœ… DeepSeekOCRProcessorå®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Flask APIã‚µãƒ¼ãƒãƒ¼ã®å®Ÿè£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # CORSæœ‰åŠ¹åŒ–\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({\n",
    "        'status': 'ok',\n",
    "        'service': 'DeepSeek-OCR API Server',\n",
    "        'gpu': torch.cuda.is_available(),\n",
    "        'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None\n",
    "    })\n",
    "\n",
    "@app.route('/ocr', methods=['POST'])\n",
    "def ocr_endpoint():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯base64ãƒ‡ãƒ¼ã‚¿\n",
    "        if 'file' in request.files:\n",
    "            file = request.files['file']\n",
    "            image_data = file.read()\n",
    "        elif 'image' in request.json:\n",
    "            image_data = request.json['image']  # base64\n",
    "        else:\n",
    "            return jsonify({'success': False, 'error': 'No image provided'}), 400\n",
    "        \n",
    "        # DeepSeek OCRå®Ÿè¡Œ\n",
    "        proc = get_processor()\n",
    "        result = proc.process_image_to_yaml(image_data)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'yaml': result['yaml'],\n",
    "            'markdown': result['markdown'],\n",
    "            'processingTime': processing_time * 1000,  # ms\n",
    "            'metadata': {\n",
    "                'modelType': 'DeepSeek-OCR',\n",
    "                'processingTime': processing_time * 1000\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "print(\"âœ… Flask APIã‚µãƒ¼ãƒãƒ¼å®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ngrokã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨èµ·å‹•\n",
    "\n",
    "**é‡è¦:** ngrokã®èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã¦ãã ã•ã„\n",
    "1. https://ngrok.com/ ã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆï¼ˆç„¡æ–™ï¼‰\n",
    "2. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‹ã‚‰èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚³ãƒ”ãƒ¼\n",
    "3. ä¸‹ã®ã‚»ãƒ«ã® `YOUR_NGROK_TOKEN` ã‚’ç½®ãæ›ãˆã¦å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok, conf\n",
    "import threading\n",
    "\n",
    "# ngrokèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šï¼ˆhttps://dashboard.ngrok.com/get-started/your-authtokenã‹ã‚‰å–å¾—ï¼‰\n",
    "NGROK_AUTH_TOKEN = \"YOUR_NGROK_TOKEN\"  # â† ã“ã“ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„\n",
    "\n",
    "if NGROK_AUTH_TOKEN == \"YOUR_NGROK_TOKEN\":\n",
    "    print(\"âš ï¸ ngrokèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ã¦ãã ã•ã„\")\n",
    "    print(\"1. https://ngrok.com/ ã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ\")\n",
    "    print(\"2. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚³ãƒ”ãƒ¼\")\n",
    "    print(\"3. ä¸Šã®ã‚»ãƒ«ã®NGROK_AUTH_TOKENã‚’ç½®ãæ›ãˆã¦ãã ã•ã„\")\n",
    "else:\n",
    "    # ngrokè¨­å®š\n",
    "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰\n",
    "    print(\"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...ï¼ˆåˆå›ã¯5-10åˆ†ã‹ã‹ã‚Šã¾ã™ï¼‰\")\n",
    "    get_processor()\n",
    "    print(\"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
    "    \n",
    "    # Flaskã‚µãƒ¼ãƒãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•\n",
    "    def run_flask():\n",
    "        app.run(port=5000)\n",
    "    \n",
    "    flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
    "    flask_thread.start()\n",
    "    \n",
    "    # ngrokãƒˆãƒ³ãƒãƒ«ä½œæˆ\n",
    "    public_url = ngrok.connect(5000)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ DeepSeek OCR APIã‚µãƒ¼ãƒãƒ¼èµ·å‹•å®Œäº†ï¼\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nğŸ“¡ å…¬é–‹URL: {public_url}\")\n",
    "    print(f\"\\nãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: {public_url}/health\")\n",
    "    print(f\"OCRã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {public_url}/ocr\")\n",
    "    print(\"\\nâš ï¸ ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ç¶šã‘ã¦ã„ã‚‹é™ã‚Šã‚µãƒ¼ãƒãƒ¼ã¯ç¨¼åƒã—ã¾ã™\")\n",
    "    print(\"âš ï¸ Colabã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ‡ã‚ŒãŸã‚‰å†èµ·å‹•ãŒå¿…è¦ã§ã™\")\n",
    "    print(\"\\nğŸ’¡ MacBook Proã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ä»¥ä¸‹ã‚’è¨­å®š:\")\n",
    "    print(f\"   DEEPSEEK_OCR_URL={public_url}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # ã‚µãƒ¼ãƒãƒ¼ã‚’ç¨¼åƒã—ç¶šã‘ã‚‹\n",
    "    import time\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒ†ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "\n",
    "APIãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# ä¸Šã§è¡¨ç¤ºã•ã‚ŒãŸå…¬é–‹URLã‚’ä½¿ç”¨\n",
    "API_URL = \"YOUR_NGROK_URL\"  # ä¾‹: https://xxxx-xx-xx-xx-xx.ngrok.io\n",
    "\n",
    "# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯\n",
    "response = requests.get(f\"{API_URL}/health\")\n",
    "print(\"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœ:\")\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
