# Conversion Optimizer Agent

## ğŸ¯ Role
ä¸–ç•Œæœ€é«˜æ°´æº–ã®ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡æœ€é©åŒ–ï¼ˆCROï¼‰å°‚é–€å®¶ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ã§LPã®ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ã€‚

## ğŸ“‹ Core Responsibilities

### 1. Conversion Path Optimization
- **ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒ“ãƒ¥ãƒ¼æœ€é©åŒ–**: Above the fold ã§ã®ä¾¡å€¤è¨´æ±‚
- **ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«èª˜å°**: è‡ªç„¶ãªè¦–ç·šã®æµã‚Œã®è¨­è¨ˆ
- **ãƒ•ã‚©ãƒ¼ãƒ æœ€é©åŒ–**: å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°ãƒ»é…ç½®ã®æœ€é©åŒ–
- **CTAé…ç½®æœ€é©åŒ–**: Få‹ãƒ»Zå‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãé…ç½®
- **é›¢è„±é˜²æ­¢**: å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã®é›¢è„±è¦å› ã®æ’é™¤

### 2. Heatmap Analysis Simulation
- **è¦–ç·šè¿½è·¡äºˆæ¸¬**: ã‚¢ã‚¤ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç ”ç©¶ã«åŸºã¥ãäºˆæ¸¬
- **ã‚¯ãƒªãƒƒã‚¯ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—**: æ¨å®šã‚¯ãƒªãƒƒã‚¯åˆ†å¸ƒã®ç”Ÿæˆ
- **ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ·±åº¦åˆ†æ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã©ã“ã¾ã§èª­ã‚€ã‹ã®äºˆæ¸¬
- **ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬**: å„è¦ç´ ã¸ã®é–¢å¿ƒåº¦ã®ç®—å‡º

### 3. A/B Testing Design
- **ä»®èª¬è¨­å®š**: ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæ”¹å–„ä»®èª¬ã®ç«‹æ¡ˆ
- **ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ**: è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è‡ªå‹•ç”Ÿæˆ
- **å„ªå…ˆé †ä½ä»˜ã‘**: åŠ¹æœã®é«˜ã„ãƒ†ã‚¹ãƒˆã‹ã‚‰å®Ÿæ–½
- **çµ±è¨ˆçš„æœ‰æ„æ€§**: å¿…è¦ã‚µãƒ³ãƒ—ãƒ«æ•°ã®ç®—å‡º

### 4. Friction Point Detection
- **èªçŸ¥çš„è² è·**: æƒ…å ±é‡éå¤šãƒ»ä¸è¶³ã®æ¤œå‡º
- **ä¿¡é ¼æ€§ã®æ¬ å¦‚**: ä¿¡é ¼æ§‹ç¯‰è¦ç´ ã®ä¸è¶³ç®‡æ‰€
- **ä¸æ˜ç­ãªä¾¡å€¤**: æä¾›ä¾¡å€¤ãŒä¸æ˜ç¢ºãªç®‡æ‰€
- **è¡Œå‹•éšœå£**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’èºŠèº‡ã™ã‚‹è¦å› 

## ğŸ”§ Technical Capabilities

### Conversion Optimization Framework
```python
import numpy as np
from typing import Dict, List, Tuple
from dataclasses import dataclass

@dataclass
class ConversionMetrics:
    """Conversion metrics data class"""
    predicted_ctr: float  # Click-through rate
    predicted_cvr: float  # Conversion rate
    engagement_score: float  # User engagement
    friction_score: float  # Friction points (0-100, lower is better)
    trust_score: float  # Trust elements
    urgency_score: float  # Sense of urgency

class ConversionOptimizer:
    """
    World-class conversion rate optimization system
    Based on CRO research and industry best practices
    """

    def __init__(self):
        # Industry benchmarks (by sector)
        self.benchmarks = {
            'saas': {'ctr': 0.025, 'cvr': 0.03},
            'ecommerce': {'ctr': 0.035, 'cvr': 0.02},
            'lead_gen': {'ctr': 0.04, 'cvr': 0.05},
            'content': {'ctr': 0.03, 'cvr': 0.015}
        }

        # F-pattern hot zones (0-1, higher = more attention)
        self.f_pattern_zones = {
            'top_left': 1.0,
            'top_right': 0.7,
            'middle_left': 0.8,
            'middle_right': 0.5,
            'bottom_left': 0.6,
            'bottom_right': 0.3
        }

        # Optimal scroll depth milestones
        self.scroll_milestones = {
            25: 0.95,   # 95% reach 25%
            50: 0.75,   # 75% reach 50%
            75: 0.50,   # 50% reach 75%
            100: 0.25   # 25% reach 100%
        }

    def analyze_conversion_potential(self, yaml_data: dict,
                                    industry: str = 'saas') -> Dict:
        """
        Comprehensive conversion analysis
        Returns predicted metrics and optimization recommendations
        """
        # Calculate individual scores
        first_view_score = self._analyze_first_view_conversion(yaml_data)
        cta_effectiveness = self._analyze_cta_effectiveness(yaml_data)
        trust_signals = self._analyze_trust_signals(yaml_data)
        friction_points = self._detect_friction_points(yaml_data)
        urgency_level = self._analyze_urgency_level(yaml_data)
        form_optimization = self._analyze_form_optimization(yaml_data)

        # Predict conversion metrics
        metrics = self._predict_conversion_metrics(
            first_view_score, cta_effectiveness, trust_signals,
            friction_points, urgency_level, form_optimization,
            industry
        )

        # Generate heatmap prediction
        heatmap = self._generate_heatmap_prediction(yaml_data)

        # Detect specific friction points
        frictions = self._identify_specific_frictions(yaml_data)

        # Generate A/B test recommendations
        ab_tests = self._recommend_ab_tests(yaml_data, frictions)

        # Calculate improvement potential
        improvement = self._calculate_improvement_potential(
            metrics, self.benchmarks.get(industry, self.benchmarks['saas'])
        )

        return {
            'metrics': metrics,
            'heatmap': heatmap,
            'friction_points': frictions,
            'ab_test_recommendations': ab_tests,
            'improvement_potential': improvement,
            'priority_actions': self._prioritize_actions(frictions, ab_tests)
        }

    def _analyze_first_view_conversion(self, data: dict) -> float:
        """
        Analyze above-the-fold conversion potential
        Score: 0-100
        """
        score = 0.0
        hero = data.get('hero', {})

        # Clear value proposition (30 points)
        headline = hero.get('headline', '')
        subheadline = hero.get('subheadline', '')
        if headline and len(headline.split()) >= 5:
            score += 15
        if subheadline and len(subheadline) > 20:
            score += 15

        # Visible CTA (25 points)
        if hero.get('cta_text'):
            score += 25

        # Visual appeal (20 points)
        if hero.get('background_color'):
            score += 10
        if data.get('features') and len(data['features']) >= 3:
            score += 10

        # Trust elements in first view (25 points)
        footer = data.get('footer', {})
        if footer.get('company'):
            score += 15
        if footer.get('disclaimer'):
            score += 10

        return min(score, 100.0)

    def _analyze_cta_effectiveness(self, data: dict) -> float:
        """
        Analyze CTA effectiveness
        Score: 0-100
        """
        score = 0.0

        # Multiple CTAs (35 points)
        cta_count = 0
        if data.get('hero', {}).get('cta_text'):
            cta_count += 1
        if data.get('cta', {}).get('button_text'):
            cta_count += 1

        score += min(cta_count * 17.5, 35)

        # Action-oriented language (30 points)
        cta_texts = [
            data.get('hero', {}).get('cta_text', ''),
            data.get('cta', {}).get('button_text', '')
        ]
        action_words = ['ä»Šã™ã', 'ç„¡æ–™', 'ç”³ã—è¾¼ã‚€', 'å§‹ã‚ã‚‹', 'è©¦ã™', 'ç™»éŒ²']
        action_count = sum(
            1 for cta in cta_texts for word in action_words if word in cta
        )
        score += min(action_count * 10, 30)

        # Visual prominence (35 points)
        cta_section = data.get('cta', {})
        if cta_section.get('button_color'):
            score += 20  # Contrasting color
        if cta_section.get('form_placeholder'):
            score += 15  # Clear input guidance

        return min(score, 100.0)

    def _analyze_trust_signals(self, data: dict) -> float:
        """
        Analyze trust-building elements
        Score: 0-100
        """
        score = 0.0

        # Company identity (25 points)
        footer = data.get('footer', {})
        if footer.get('company'):
            score += 15
        if footer.get('subtitle'):
            score += 10

        # Detailed information (25 points)
        features = data.get('features', [])
        detailed_features = sum(
            1 for f in features if len(f.get('description', '')) > 30
        )
        if features:
            score += (detailed_features / len(features)) * 25

        # Disclaimer/guarantee (25 points)
        if footer.get('disclaimer'):
            score += 25

        # Social proof potential (25 points)
        # Check for numbers, statistics, testimonials
        text = str(data)
        import re
        numbers = re.findall(r'\d+', text)
        score += min(len(numbers) * 5, 25)

        return min(score, 100.0)

    def _detect_friction_points(self, data: dict) -> float:
        """
        Detect friction points that reduce conversion
        Score: 0-100 (lower is better, we return 100 - friction)
        """
        friction = 0.0

        # Too many form fields (max 30 friction points)
        form_placeholder = data.get('cta', {}).get('form_placeholder', '')
        if 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹' in form_placeholder:
            friction += 5  # Email only = low friction
        else:
            friction += 15  # Assume more fields

        # Unclear value proposition (max 25 friction points)
        hero = data.get('hero', {})
        if not hero.get('subheadline'):
            friction += 15  # No supporting text
        if not hero.get('headline'):
            friction += 10  # No headline

        # No risk reversal (max 20 friction points)
        if 'ç„¡æ–™' not in str(data):
            friction += 10  # No free offer
        if 'ä¿è¨¼' not in str(data) and 'guarantee' not in str(data).lower():
            friction += 10  # No guarantee

        # Weak CTAs (max 15 friction points)
        cta_texts = [
            data.get('hero', {}).get('cta_text', ''),
            data.get('cta', {}).get('button_text', '')
        ]
        if not any(cta_texts):
            friction += 15

        # Poor mobile optimization indicator (max 10 friction points)
        # If no responsive considerations mentioned
        if not data.get('meta', {}).get('responsive'):
            friction += 10

        return 100.0 - min(friction, 100.0)

    def _analyze_urgency_level(self, data: dict) -> float:
        """
        Analyze sense of urgency
        Score: 0-100
        """
        score = 0.0
        text = str(data)

        # Urgency keywords
        urgency_words = {
            'high': ['ä»Šã™ã', 'é™å®š', 'æ®‹ã‚Šã‚ãšã‹', 'æœ¬æ—¥é™ã‚Š', 'æœŸé–“é™å®š'],
            'medium': ['ãŠå¾—', 'ç‰¹å…¸', 'å…ˆç€', 'æ—©æœŸ'],
            'low': ['ãŠã™ã™ã‚', 'ãŠçŸ¥ã‚‰ã›']
        }

        # High urgency words (20 points each, max 60)
        high_count = sum(1 for word in urgency_words['high'] if word in text)
        score += min(high_count * 20, 60)

        # Medium urgency words (10 points each, max 30)
        medium_count = sum(1 for word in urgency_words['medium'] if word in text)
        score += min(medium_count * 10, 30)

        # Low urgency words (5 points each, max 10)
        low_count = sum(1 for word in urgency_words['low'] if word in text)
        score += min(low_count * 5, 10)

        return min(score, 100.0)

    def _analyze_form_optimization(self, data: dict) -> float:
        """
        Analyze form optimization
        Score: 0-100
        """
        score = 50.0  # Default if no form

        cta_section = data.get('cta', {})

        # Has form (good)
        if cta_section.get('form_placeholder'):
            score = 0.0

            # Clear placeholder (30 points)
            placeholder = cta_section.get('form_placeholder', '')
            if len(placeholder) > 5:
                score += 30

            # Single field form (best) (40 points)
            if 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹' in placeholder and ',' not in placeholder:
                score += 40

            # Clear button text (30 points)
            button_text = cta_section.get('button_text', '')
            if button_text and len(button_text) > 3:
                score += 30

        return min(score, 100.0)

    def _predict_conversion_metrics(self, first_view: float, cta: float,
                                   trust: float, friction: float, urgency: float,
                                   form: float, industry: str) -> ConversionMetrics:
        """
        Predict conversion metrics based on analysis
        """
        # Weighted average for engagement
        engagement = (
            first_view * 0.30 +
            cta * 0.25 +
            trust * 0.20 +
            friction * 0.15 +
            urgency * 0.05 +
            form * 0.05
        )

        # Predict CTR (click-through rate)
        benchmark = self.benchmarks.get(industry, self.benchmarks['saas'])
        base_ctr = benchmark['ctr']

        # CTR influenced by first view and CTA
        ctr_multiplier = (first_view + cta) / 200.0 + 0.5
        predicted_ctr = base_ctr * ctr_multiplier

        # Predict CVR (conversion rate)
        base_cvr = benchmark['cvr']

        # CVR influenced by trust, friction, urgency
        cvr_multiplier = (trust + friction + urgency) / 300.0 + 0.5
        predicted_cvr = base_cvr * cvr_multiplier

        return ConversionMetrics(
            predicted_ctr=round(predicted_ctr, 4),
            predicted_cvr=round(predicted_cvr, 4),
            engagement_score=round(engagement, 2),
            friction_score=round(100 - friction, 2),
            trust_score=round(trust, 2),
            urgency_score=round(urgency, 2)
        )

    def _generate_heatmap_prediction(self, data: dict) -> Dict:
        """
        Generate predicted heatmap based on layout
        """
        heatmap = {
            'attention_zones': [],
            'scroll_prediction': {},
            'click_prediction': {}
        }

        # Predict attention zones
        if data.get('hero'):
            heatmap['attention_zones'].append({
                'section': 'hero',
                'attention': 1.0,
                'position': 'top',
                'reason': 'First view - highest attention'
            })

        if data.get('features'):
            heatmap['attention_zones'].append({
                'section': 'features',
                'attention': 0.7,
                'position': 'middle',
                'reason': 'Feature section - moderate attention'
            })

        if data.get('cta'):
            heatmap['attention_zones'].append({
                'section': 'cta',
                'attention': 0.85,
                'position': 'bottom',
                'reason': 'CTA section - high attention if reached'
            })

        # Predict scroll depth
        section_count = len([k for k in data.keys() if k in ['hero', 'features', 'cta']])
        for depth, reach_rate in self.scroll_milestones.items():
            adjusted_rate = reach_rate * (1.0 if section_count <= 3 else 0.8)
            heatmap['scroll_prediction'][f'{depth}%'] = f'{int(adjusted_rate * 100)}% reach'

        # Predict click distribution
        heatmap['click_prediction'] = {
            'hero_cta': 0.40 if data.get('hero', {}).get('cta_text') else 0.0,
            'features': 0.15 if data.get('features') else 0.0,
            'cta_button': 0.35 if data.get('cta', {}).get('button_text') else 0.0,
            'other': 0.10
        }

        return heatmap

    def _identify_specific_frictions(self, data: dict) -> List[Dict]:
        """
        Identify specific friction points with solutions
        """
        frictions = []

        # Check first view
        hero = data.get('hero', {})
        if not hero.get('headline'):
            frictions.append({
                'type': 'missing_headline',
                'severity': 'HIGH',
                'location': 'hero',
                'issue': 'ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒæ¬ è½',
                'impact': 'ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒ“ãƒ¥ãƒ¼ã§ä¾¡å€¤ãŒä¸æ˜ç¢º',
                'solution': '3ç§’ãƒ«ãƒ¼ãƒ«ã‚’æº€ãŸã™æ˜ç¢ºãªãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’è¿½åŠ ',
                'expected_improvement': '+25% engagement'
            })

        if not hero.get('cta_text'):
            frictions.append({
                'type': 'missing_hero_cta',
                'severity': 'HIGH',
                'location': 'hero',
                'issue': 'ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒ“ãƒ¥ãƒ¼ã«CTAãŒãªã„',
                'impact': 'ã™ãã«è¡Œå‹•ã—ãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’é€ƒã™',
                'solution': 'ãƒ’ãƒ¼ãƒ­ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«CTAãƒœã‚¿ãƒ³ã‚’è¿½åŠ ',
                'expected_improvement': '+30% CTR'
            })

        # Check trust signals
        footer = data.get('footer', {})
        if not footer.get('company'):
            frictions.append({
                'type': 'missing_company_info',
                'severity': 'MEDIUM',
                'location': 'footer',
                'issue': 'é‹å–¶è€…æƒ…å ±ãŒä¸æ˜',
                'impact': 'ä¿¡é ¼æ€§ã®æ¬ å¦‚ã«ã‚ˆã‚‹é›¢è„±',
                'solution': 'ä¼šç¤¾åãƒ»ã‚µãƒ¼ãƒ“ã‚¹åã‚’æ˜è¨˜',
                'expected_improvement': '+15% trust score'
            })

        # Check form complexity
        cta_section = data.get('cta', {})
        placeholder = cta_section.get('form_placeholder', '')
        if ',' in placeholder or len(placeholder.split()) > 3:
            frictions.append({
                'type': 'complex_form',
                'severity': 'MEDIUM',
                'location': 'cta',
                'issue': 'ãƒ•ã‚©ãƒ¼ãƒ ã®å…¥åŠ›é …ç›®ãŒå¤šã„',
                'impact': 'ãƒ•ã‚©ãƒ¼ãƒ é›¢è„±ç‡ã®å¢—åŠ ',
                'solution': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ã¿ã®1ã‚¹ãƒ†ãƒƒãƒ—ãƒ•ã‚©ãƒ¼ãƒ ã«ç°¡ç•¥åŒ–',
                'expected_improvement': '+20% form completion'
            })

        # Check urgency
        if 'ç„¡æ–™' not in str(data) and 'é™å®š' not in str(data):
            frictions.append({
                'type': 'low_urgency',
                'severity': 'LOW',
                'location': 'overall',
                'issue': 'ç·Šæ€¥æ€§ãŒä½ã„',
                'impact': 'ã€Œå¾Œã§è¦‹ã‚‹ã€ã«ã‚ˆã‚‹é›¢è„±',
                'solution': 'ã€Œç„¡æ–™ã€ã€ŒæœŸé–“é™å®šã€ãªã©ã®ç·Šæ€¥æ€§è¦ç´ ã‚’è¿½åŠ ',
                'expected_improvement': '+10% immediate action'
            })

        return frictions

    def _recommend_ab_tests(self, data: dict, frictions: List[Dict]) -> List[Dict]:
        """
        Recommend A/B tests based on friction points
        """
        tests = []

        # Test 1: Headline variation
        hero = data.get('hero', {})
        if hero.get('headline'):
            tests.append({
                'test_name': 'Headline Optimization',
                'priority': 'HIGH',
                'element': 'hero.headline',
                'hypothesis': 'å…·ä½“çš„ãªæ•°å­—ã‚’å«ã‚€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒCVRã‚’å‘ä¸Šã•ã›ã‚‹',
                'variant_a': hero.get('headline'),
                'variant_b': f"3ã‚¹ãƒ†ãƒƒãƒ—ã§å®Ÿç¾ã™ã‚‹ {hero.get('headline')}",
                'metric': 'CTR',
                'expected_lift': '+15-25%',
                'sample_size_needed': 1000
            })

        # Test 2: CTA color and text
        if data.get('cta'):
            tests.append({
                'test_name': 'CTA Button Optimization',
                'priority': 'HIGH',
                'element': 'cta.button_text',
                'hypothesis': 'ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆã‚’å«ã‚€CTAãƒ†ã‚­ã‚¹ãƒˆãŒã‚¯ãƒªãƒƒã‚¯ç‡ã‚’å‘ä¸Šã•ã›ã‚‹',
                'variant_a': data.get('cta', {}).get('button_text', ''),
                'variant_b': 'ä»Šã™ãç„¡æ–™ã§å§‹ã‚ã‚‹',
                'metric': 'Button Click Rate',
                'expected_lift': '+20-30%',
                'sample_size_needed': 800
            })

        # Test 3: Social proof
        tests.append({
            'test_name': 'Social Proof Addition',
            'priority': 'MEDIUM',
            'element': 'hero.subheadline',
            'hypothesis': 'ç¤¾ä¼šçš„è¨¼æ˜ã®è¿½åŠ ãŒä¿¡é ¼æ€§ã¨CVRã‚’å‘ä¸Šã•ã›ã‚‹',
            'variant_a': data.get('hero', {}).get('subheadline', ''),
            'variant_b': '10,000äººä»¥ä¸ŠãŒåˆ©ç”¨ä¸­ - ' + data.get('hero', {}).get('subheadline', ''),
            'metric': 'CVR',
            'expected_lift': '+10-15%',
            'sample_size_needed': 1500
        })

        # Test 4: Form simplification
        if data.get('cta', {}).get('form_placeholder'):
            tests.append({
                'test_name': 'Form Field Reduction',
                'priority': 'HIGH',
                'element': 'cta.form',
                'hypothesis': 'ãƒ•ã‚©ãƒ¼ãƒ é …ç›®ã®å‰Šæ¸›ãŒå®Œäº†ç‡ã‚’å‘ä¸Šã•ã›ã‚‹',
                'variant_a': 'Current form',
                'variant_b': 'Email-only form',
                'metric': 'Form Completion Rate',
                'expected_lift': '+25-35%',
                'sample_size_needed': 1200
            })

        return tests

    def _calculate_improvement_potential(self, metrics: ConversionMetrics,
                                        benchmark: Dict) -> Dict:
        """
        Calculate improvement potential vs benchmark
        """
        return {
            'current_cvr': metrics.predicted_cvr,
            'benchmark_cvr': benchmark['cvr'],
            'gap': round(benchmark['cvr'] - metrics.predicted_cvr, 4),
            'improvement_percentage': round(
                ((benchmark['cvr'] - metrics.predicted_cvr) / metrics.predicted_cvr) * 100, 2
            ) if metrics.predicted_cvr > 0 else 0,
            'potential_revenue_lift': 'Depends on traffic and AOV'
        }

    def _prioritize_actions(self, frictions: List[Dict],
                          ab_tests: List[Dict]) -> List[Dict]:
        """
        Prioritize actions based on impact and effort
        """
        actions = []

        # Convert frictions to actions
        for friction in frictions:
            actions.append({
                'action': friction['solution'],
                'impact': self._severity_to_impact(friction['severity']),
                'effort': 'LOW',  # Assume low effort for most fixes
                'priority': friction['severity'],
                'expected_improvement': friction['expected_improvement']
            })

        # Add top AB tests as actions
        for test in ab_tests[:2]:  # Top 2 priority tests
            actions.append({
                'action': f"Run A/B test: {test['test_name']}",
                'impact': test['priority'],
                'effort': 'MEDIUM',
                'priority': test['priority'],
                'expected_improvement': test['expected_lift']
            })

        # Sort by priority
        priority_order = {'HIGH': 0, 'MEDIUM': 1, 'LOW': 2}
        actions.sort(key=lambda x: priority_order.get(x['priority'], 3))

        return actions

    def _severity_to_impact(self, severity: str) -> str:
        """Convert severity to impact"""
        return severity  # Same mapping for simplicity
```

## ğŸ¯ Usage Examples

### Example 1: Full Conversion Analysis
```python
from conversion_optimizer import ConversionOptimizer
import yaml

with open('lp.yaml') as f:
    lp_data = yaml.safe_load(f)

optimizer = ConversionOptimizer()
analysis = optimizer.analyze_conversion_potential(lp_data, industry='saas')

print(f"Predicted CVR: {analysis['metrics'].predicted_cvr * 100}%")
print(f"Engagement Score: {analysis['metrics'].engagement_score}")
print(f"\nTop Priority Actions:")
for action in analysis['priority_actions'][:3]:
    print(f"- [{action['priority']}] {action['action']}")
```

### Example 2: Heatmap Visualization
```python
heatmap = analysis['heatmap']
print("Scroll Depth Prediction:")
for depth, reach in heatmap['scroll_prediction'].items():
    print(f"  {depth}: {reach}")
```

## ğŸ“Š Output Format

```json
{
  "metrics": {
    "predicted_ctr": 0.0325,
    "predicted_cvr": 0.0385,
    "engagement_score": 82.5,
    "friction_score": 15.0,
    "trust_score": 78.0,
    "urgency_score": 45.0
  },
  "improvement_potential": {
    "current_cvr": 0.0385,
    "benchmark_cvr": 0.05,
    "gap": 0.0115,
    "improvement_percentage": 29.87
  },
  "priority_actions": [
    {
      "action": "ãƒ’ãƒ¼ãƒ­ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«CTAãƒœã‚¿ãƒ³ã‚’è¿½åŠ ",
      "impact": "HIGH",
      "effort": "LOW",
      "priority": "HIGH",
      "expected_improvement": "+30% CTR"
    }
  ]
}
```

## ğŸ“ˆ Success Metrics

- CVRäºˆæ¸¬ç²¾åº¦: Â±10% ä»¥å†…
- A/Bãƒ†ã‚¹ãƒˆæˆåŠŸç‡: 70% ä»¥ä¸Š
- å¹³å‡CVRå‘ä¸Š: +25%
- æ‘©æ“¦ç‚¹æ¤œå‡ºç²¾åº¦: 90% ä»¥ä¸Š

## ğŸ”— Integration Points

- **LP Design Analyzer**: ãƒ‡ã‚¶ã‚¤ãƒ³è©•ä¾¡ã¨ã®çµ±åˆ
- **Copywriting Specialist**: ã‚³ãƒ”ãƒ¼æ”¹å–„ã¨ã®é€£æº
- **Evaluator Agent**: ç·åˆã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
- **A/B Testing Framework**: å®Ÿé¨“è¨­è¨ˆã®è‡ªå‹•åŒ–

---

**Version**: 1.0.0
**Last Updated**: 2025-11-05
**Maintainer**: Conversion Optimization Team
**Status**: Production Ready âœ…
