{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek OCR API Server for Google Colab\n",
    "\n",
    "このノートブックはGoogle Colab上でDeepSeek OCRをAPIサーバーとして実行します。\n",
    "\n",
    "## 使い方\n",
    "1. ランタイム → ランタイムのタイプを変更 → GPU を選択\n",
    "2. すべてのセルを順番に実行\n",
    "3. ngrok URLをコピーして、MacBook ProのアプリケーションのDEEPSEEK_OCR_URLに設定\n",
    "\n",
    "## 必要なもの\n",
    "- Google アカウント\n",
    "- ngrok アカウント（無料）: https://ngrok.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 依存関係のインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek OCR依存関係\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q transformers==4.46.3\n",
    "!pip install -q tokenizers==0.20.3\n",
    "!pip install -q einops addict easydict\n",
    "!pip install -q Pillow PyYAML opencv-python-headless\n",
    "!pip install -q flask flask-cors pyngrok\n",
    "\n",
    "# Flash Attention（オプション、高速化）\n",
    "!pip install -q flash-attn==2.7.3 --no-build-isolation || echo \"Flash Attention インストール失敗（スキップ）\"\n",
    "\n",
    "print(\"✅ インストール完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DeepSeek OCRプロセッサーの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "class DeepSeekOCRProcessor:\n",
    "    \"\"\"DeepSeek-OCRを使用してLP画像を処理\"\"\"\n",
    "\n",
    "    def __init__(self, model_name='deepseek-ai/DeepSeek-OCR'):\n",
    "        print(f\"Loading DeepSeek-OCR model: {model_name}\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            _attn_implementation='flash_attention_2',\n",
    "            trust_remote_code=True,\n",
    "            use_safetensors=True\n",
    "        )\n",
    "\n",
    "        self.model = self.model.eval().cuda().to(torch.bfloat16)\n",
    "        print(\"✅ Model loaded successfully\")\n",
    "\n",
    "    def process_image_to_yaml(self, image_data, output_path='/tmp/deepseek_output'):\n",
    "        \"\"\"\n",
    "        画像データ（base64またはバイト）からYAMLを生成\n",
    "        \"\"\"\n",
    "        # 一時ファイルに保存\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        temp_image_path = os.path.join(output_path, 'temp_image.png')\n",
    "        \n",
    "        # 画像データを保存\n",
    "        if isinstance(image_data, str):\n",
    "            # base64デコード\n",
    "            image_bytes = base64.b64decode(image_data)\n",
    "            with open(temp_image_path, 'wb') as f:\n",
    "                f.write(image_bytes)\n",
    "        else:\n",
    "            # バイトデータ\n",
    "            with open(temp_image_path, 'wb') as f:\n",
    "                f.write(image_data)\n",
    "        \n",
    "        # DeepSeek OCR実行\n",
    "        prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n",
    "        \n",
    "        result = self.model.infer(\n",
    "            self.tokenizer,\n",
    "            prompt=prompt,\n",
    "            image_file=temp_image_path,\n",
    "            output_path=output_path,\n",
    "            base_size=1024,\n",
    "            image_size=640,\n",
    "            crop_mode=True,\n",
    "            save_results=False,\n",
    "            test_compress=True\n",
    "        )\n",
    "        \n",
    "        # Markdownを取得\n",
    "        if isinstance(result, dict):\n",
    "            markdown_text = result.get('text', '') or result.get('content', '')\n",
    "        else:\n",
    "            markdown_text = str(result)\n",
    "        \n",
    "        # Markdown → YAML変換\n",
    "        yaml_text = self.markdown_to_yaml(markdown_text)\n",
    "        \n",
    "        return {\n",
    "            'yaml': yaml_text,\n",
    "            'markdown': markdown_text\n",
    "        }\n",
    "\n",
    "    def markdown_to_yaml(self, markdown_text):\n",
    "        \"\"\"Markdown → YAML変換（簡易版）\"\"\"\n",
    "        sections = []\n",
    "        lines = markdown_text.split('\\n')\n",
    "        current_section = None\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            if line.startswith('#'):\n",
    "                if current_section:\n",
    "                    sections.append(current_section)\n",
    "                \n",
    "                heading_text = line.lstrip('#').strip()\n",
    "                current_section = {\n",
    "                    'type': 'content',\n",
    "                    'texts': [{'content': heading_text, 'role': 'headline'}],\n",
    "                    'buttons': [],\n",
    "                    'items': []\n",
    "                }\n",
    "            elif current_section:\n",
    "                current_section['texts'].append({'content': line, 'role': 'body'})\n",
    "        \n",
    "        if current_section:\n",
    "            sections.append(current_section)\n",
    "        \n",
    "        yaml_data = {\n",
    "            'meta': {'generator': 'DeepSeek-OCR'},\n",
    "            'sections': {f'section{i+1}': s for i, s in enumerate(sections)}\n",
    "        }\n",
    "        \n",
    "        return yaml.dump(yaml_data, allow_unicode=True, default_flow_style=False)\n",
    "\n",
    "# グローバルインスタンス（初回ロード時のみ）\n",
    "processor = None\n",
    "\n",
    "def get_processor():\n",
    "    global processor\n",
    "    if processor is None:\n",
    "        processor = DeepSeekOCRProcessor()\n",
    "    return processor\n",
    "\n",
    "print(\"✅ DeepSeekOCRProcessor定義完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Flask APIサーバーの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # CORS有効化\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({\n",
    "        'status': 'ok',\n",
    "        'service': 'DeepSeek-OCR API Server',\n",
    "        'gpu': torch.cuda.is_available(),\n",
    "        'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None\n",
    "    })\n",
    "\n",
    "@app.route('/ocr', methods=['POST'])\n",
    "def ocr_endpoint():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ファイルアップロードまたはbase64データ\n",
    "        if 'file' in request.files:\n",
    "            file = request.files['file']\n",
    "            image_data = file.read()\n",
    "        elif 'image' in request.json:\n",
    "            image_data = request.json['image']  # base64\n",
    "        else:\n",
    "            return jsonify({'success': False, 'error': 'No image provided'}), 400\n",
    "        \n",
    "        # DeepSeek OCR実行\n",
    "        proc = get_processor()\n",
    "        result = proc.process_image_to_yaml(image_data)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'yaml': result['yaml'],\n",
    "            'markdown': result['markdown'],\n",
    "            'processingTime': processing_time * 1000,  # ms\n",
    "            'metadata': {\n",
    "                'modelType': 'DeepSeek-OCR',\n",
    "                'processingTime': processing_time * 1000\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "print(\"✅ Flask APIサーバー定義完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ngrokのセットアップと起動\n",
    "\n",
    "**重要:** ngrokの認証トークンを取得してください\n",
    "1. https://ngrok.com/ でアカウント作成（無料）\n",
    "2. ダッシュボードから認証トークンをコピー\n",
    "3. 下のセルの `YOUR_NGROK_TOKEN` を置き換えて実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok, conf\n",
    "import threading\n",
    "\n",
    "# ngrok認証トークンを設定（https://dashboard.ngrok.com/get-started/your-authtokenから取得）\n",
    "NGROK_AUTH_TOKEN = \"YOUR_NGROK_TOKEN\"  # ← ここを変更してください\n",
    "\n",
    "if NGROK_AUTH_TOKEN == \"YOUR_NGROK_TOKEN\":\n",
    "    print(\"⚠️ ngrok認証トークンを設定してください\")\n",
    "    print(\"1. https://ngrok.com/ でアカウント作成\")\n",
    "    print(\"2. ダッシュボードからトークンをコピー\")\n",
    "    print(\"3. 上のセルのNGROK_AUTH_TOKENを置き換えてください\")\n",
    "else:\n",
    "    # ngrok設定\n",
    "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "    \n",
    "    # モデルを事前ロード\n",
    "    print(\"モデルをロード中...（初回は5-10分かかります）\")\n",
    "    get_processor()\n",
    "    print(\"✅ モデルロード完了\")\n",
    "    \n",
    "    # Flaskサーバーをバックグラウンドで起動\n",
    "    def run_flask():\n",
    "        app.run(port=5000)\n",
    "    \n",
    "    flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
    "    flask_thread.start()\n",
    "    \n",
    "    # ngrokトンネル作成\n",
    "    public_url = ngrok.connect(5000)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎉 DeepSeek OCR APIサーバー起動完了！\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n📡 公開URL: {public_url}\")\n",
    "    print(f\"\\nヘルスチェック: {public_url}/health\")\n",
    "    print(f\"OCRエンドポイント: {public_url}/ocr\")\n",
    "    print(\"\\n⚠️ このセルを実行し続けている限りサーバーは稼働します\")\n",
    "    print(\"⚠️ Colabセッションが切れたら再起動が必要です\")\n",
    "    print(\"\\n💡 MacBook Proのアプリケーションで以下を設定:\")\n",
    "    print(f\"   DEEPSEEK_OCR_URL={public_url}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # サーバーを稼働し続ける\n",
    "    import time\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nサーバーを停止しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト（オプション）\n",
    "\n",
    "APIが正常に動作しているかテストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# 上で表示された公開URLを使用\n",
    "API_URL = \"YOUR_NGROK_URL\"  # 例: https://xxxx-xx-xx-xx-xx.ngrok.io\n",
    "\n",
    "# ヘルスチェック\n",
    "response = requests.get(f\"{API_URL}/health\")\n",
    "print(\"ヘルスチェック結果:\")\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
