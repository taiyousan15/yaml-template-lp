{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek OCR API Server for Google Colab (Cloudflare Tunnel版)\n",
    "\n",
    "このノートブックはGoogle Colab上でDeepSeek OCRをAPIサーバーとして実行します。\n",
    "\n",
    "## Cloudflare Tunnelの利点\n",
    "- ✅ **認証トークン不要**（ngrokより簡単）\n",
    "- ✅ **完全無料**\n",
    "- ✅ **安定性が高い**\n",
    "- ✅ **セットアップが簡単**\n",
    "\n",
    "## 使い方\n",
    "1. ランタイム → ランタイムのタイプを変更 → **GPU** を選択\n",
    "2. すべてのセルを順番に実行\n",
    "3. 表示されたCloudflare URLをコピーして、MacBook Proの`.env`に設定\n",
    "\n",
    "## 必要なもの\n",
    "- Google アカウントのみ（追加登録不要！）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cloudflaredのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloudflaredのインストール\n",
    "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
    "!sudo dpkg -i cloudflared-linux-amd64.deb\n",
    "!rm cloudflared-linux-amd64.deb\n",
    "\n",
    "# バージョン確認\n",
    "!cloudflared --version\n",
    "\n",
    "print(\"✅ Cloudflaredインストール完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 依存関係のインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek OCR依存関係\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q transformers==4.46.3\n",
    "!pip install -q tokenizers==0.20.3\n",
    "!pip install -q einops addict easydict\n",
    "!pip install -q Pillow PyYAML opencv-python-headless\n",
    "!pip install -q flask flask-cors\n",
    "\n",
    "# Flash Attention（オプション、高速化）\n",
    "!pip install -q flash-attn==2.7.3 --no-build-isolation || echo \"Flash Attention インストール失敗（スキップ）\"\n",
    "\n",
    "print(\"✅ 依存関係インストール完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DeepSeek OCRプロセッサーの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "class DeepSeekOCRProcessor:\n",
    "    \"\"\"DeepSeek-OCRを使用してLP画像を処理\"\"\"\n",
    "\n",
    "    def __init__(self, model_name='deepseek-ai/DeepSeek-OCR'):\n",
    "        print(f\"Loading DeepSeek-OCR model: {model_name}\")\n",
    "        print(\"初回は5-10分かかります。しばらくお待ちください...\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            _attn_implementation='flash_attention_2',\n",
    "            trust_remote_code=True,\n",
    "            use_safetensors=True\n",
    "        )\n",
    "\n",
    "        self.model = self.model.eval().cuda().to(torch.bfloat16)\n",
    "        print(\"✅ Model loaded successfully\")\n",
    "\n",
    "    def process_image_to_yaml(self, image_data, output_path='/tmp/deepseek_output'):\n",
    "        \"\"\"\n",
    "        画像データ（base64またはバイト）からYAMLを生成\n",
    "        \"\"\"\n",
    "        # 一時ディレクトリの作成\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        temp_image_path = os.path.join(output_path, 'temp_image.png')\n",
    "        \n",
    "        # 画像データを保存\n",
    "        if isinstance(image_data, str):\n",
    "            # base64デコード\n",
    "            image_bytes = base64.b64decode(image_data)\n",
    "            with open(temp_image_path, 'wb') as f:\n",
    "                f.write(image_bytes)\n",
    "        else:\n",
    "            # バイトデータ\n",
    "            with open(temp_image_path, 'wb') as f:\n",
    "                f.write(image_data)\n",
    "        \n",
    "        # DeepSeek OCR実行\n",
    "        prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n",
    "        \n",
    "        result = self.model.infer(\n",
    "            self.tokenizer,\n",
    "            prompt=prompt,\n",
    "            image_file=temp_image_path,\n",
    "            output_path=output_path,\n",
    "            base_size=1024,\n",
    "            image_size=640,\n",
    "            crop_mode=True,\n",
    "            save_results=False,\n",
    "            test_compress=True\n",
    "        )\n",
    "        \n",
    "        # Markdownを取得\n",
    "        if isinstance(result, dict):\n",
    "            markdown_text = result.get('text', '') or result.get('content', '')\n",
    "        else:\n",
    "            markdown_text = str(result)\n",
    "        \n",
    "        # Markdown → YAML変換\n",
    "        yaml_text = self.markdown_to_yaml(markdown_text)\n",
    "        \n",
    "        return {\n",
    "            'yaml': yaml_text,\n",
    "            'markdown': markdown_text\n",
    "        }\n",
    "\n",
    "    def markdown_to_yaml(self, markdown_text):\n",
    "        \"\"\"Markdown → YAML変換（簡易版）\"\"\"\n",
    "        sections = []\n",
    "        lines = markdown_text.split('\\n')\n",
    "        current_section = None\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            if line.startswith('#'):\n",
    "                if current_section:\n",
    "                    sections.append(current_section)\n",
    "                \n",
    "                heading_text = line.lstrip('#').strip()\n",
    "                current_section = {\n",
    "                    'type': 'content',\n",
    "                    'texts': [{'content': heading_text, 'role': 'headline'}],\n",
    "                    'buttons': [],\n",
    "                    'items': []\n",
    "                }\n",
    "            elif current_section:\n",
    "                current_section['texts'].append({'content': line, 'role': 'body'})\n",
    "        \n",
    "        if current_section:\n",
    "            sections.append(current_section)\n",
    "        \n",
    "        if not sections:\n",
    "            sections.append({\n",
    "                'type': 'content',\n",
    "                'texts': [{'content': markdown_text[:500], 'role': 'body'}],\n",
    "                'buttons': [],\n",
    "                'items': []\n",
    "            })\n",
    "        \n",
    "        yaml_data = {\n",
    "            'meta': {\n",
    "                'generator': 'DeepSeek-OCR',\n",
    "                'template_version': '2.0'\n",
    "            },\n",
    "            'sections': {f'section{i+1}': s for i, s in enumerate(sections)}\n",
    "        }\n",
    "        \n",
    "        return yaml.dump(yaml_data, allow_unicode=True, default_flow_style=False)\n",
    "\n",
    "# グローバルインスタンス（初回ロード時のみ）\n",
    "processor = None\n",
    "\n",
    "def get_processor():\n",
    "    global processor\n",
    "    if processor is None:\n",
    "        processor = DeepSeekOCRProcessor()\n",
    "    return processor\n",
    "\n",
    "print(\"✅ DeepSeekOCRProcessor定義完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Flask APIサーバーの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # CORS有効化\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({\n",
    "        'status': 'ok',\n",
    "        'service': 'DeepSeek-OCR API Server (Cloudflare Tunnel)',\n",
    "        'gpu': torch.cuda.is_available(),\n",
    "        'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None\n",
    "    })\n",
    "\n",
    "@app.route('/ocr', methods=['POST'])\n",
    "def ocr_endpoint():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ファイルアップロードまたはbase64データ\n",
    "        if 'file' in request.files:\n",
    "            file = request.files['file']\n",
    "            image_data = file.read()\n",
    "        elif request.is_json and 'image' in request.json:\n",
    "            image_data = request.json['image']  # base64\n",
    "        else:\n",
    "            return jsonify({'success': False, 'error': 'No image provided'}), 400\n",
    "        \n",
    "        # DeepSeek OCR実行\n",
    "        proc = get_processor()\n",
    "        result = proc.process_image_to_yaml(image_data)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'yaml': result['yaml'],\n",
    "            'markdown': result['markdown'],\n",
    "            'processingTime': processing_time * 1000,  # ms\n",
    "            'metadata': {\n",
    "                'modelType': 'DeepSeek-OCR',\n",
    "                'processingTime': processing_time * 1000\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "print(\"✅ Flask APIサーバー定義完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cloudflare Tunnelの起動\n",
    "\n",
    "**認証トークン不要！** このセルを実行するだけでOKです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import subprocess\n",
    "import time\n",
    "import re\n",
    "\n",
    "# モデルを事前ロード\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📦 DeepSeek-OCRモデルをロード中...\")\n",
    "print(\"初回は5-10分かかります。コーヒーでも飲んでお待ちください☕\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "get_processor()\n",
    "\n",
    "print(\"\\n✅ モデルロード完了\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🚀 APIサーバーを起動中...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Flaskサーバーをバックグラウンドで起動\n",
    "def run_flask():\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)\n",
    "\n",
    "flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
    "flask_thread.start()\n",
    "\n",
    "# Flaskが起動するまで待機\n",
    "time.sleep(3)\n",
    "\n",
    "# Cloudflare Tunnelを起動\n",
    "print(\"🌐 Cloudflare Tunnelを起動中...\\n\")\n",
    "\n",
    "cloudflared_process = subprocess.Popen(\n",
    "    ['cloudflared', 'tunnel', '--url', 'http://localhost:5000'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "# Cloudflare URLを取得\n",
    "public_url = None\n",
    "for line in cloudflared_process.stdout:\n",
    "    print(line.strip())\n",
    "    \n",
    "    # URLを抽出\n",
    "    if 'trycloudflare.com' in line or 'https://' in line:\n",
    "        match = re.search(r'https://[a-zA-Z0-9-]+\\.trycloudflare\\.com', line)\n",
    "        if match:\n",
    "            public_url = match.group(0)\n",
    "            break\n",
    "\n",
    "if public_url:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎉 DeepSeek OCR APIサーバー起動完了！\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n📡 公開URL: {public_url}\")\n",
    "    print(f\"\\n✅ ヘルスチェック: {public_url}/health\")\n",
    "    print(f\"✅ OCRエンドポイント: {public_url}/ocr\")\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"💡 MacBook Proでの設定方法:\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"\\n1. .envファイルに以下を追加:\")\n",
    "    print(f\"   DEEPSEEK_COLAB_URL={public_url}\")\n",
    "    print(\"\\n2. アプリケーションを起動:\")\n",
    "    print(\"   npm run dev\")\n",
    "    print(\"\\n3. http://localhost:3000 にアクセス\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"⚠️  重要な注意事項\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"• このセルを実行し続けている限りサーバーは稼働します\")\n",
    "    print(\"• Colabセッションが切れたら再起動が必要です（無料版:12時間）\")\n",
    "    print(\"• URLはセッションごとに変わります\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # サーバーを稼働し続ける\n",
    "    try:\n",
    "        cloudflared_process.wait()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⏹️  サーバーを停止しました\")\n",
    "        cloudflared_process.terminate()\n",
    "else:\n",
    "    print(\"\\n⚠️ Cloudflare URLの取得に失敗しました\")\n",
    "    print(\"上記のログを確認してください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト（オプション）\n",
    "\n",
    "別のセルで、APIが正常に動作しているかテストできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# 上で表示された公開URLを使用\n",
    "API_URL = \"YOUR_CLOUDFLARE_URL\"  # 例: https://xxxx.trycloudflare.com\n",
    "\n",
    "if API_URL != \"YOUR_CLOUDFLARE_URL\":\n",
    "    # ヘルスチェック\n",
    "    try:\n",
    "        response = requests.get(f\"{API_URL}/health\", timeout=10)\n",
    "        print(\"✅ ヘルスチェック成功:\")\n",
    "        print(response.json())\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ヘルスチェック失敗: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ API_URLを設定してください\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
